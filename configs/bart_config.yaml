# BART-specific Configuration - Optimized for RTX 3060

# Data Configuration
data:
  raw_dir: "./data/raw"
  processed_dir: "./data/processed"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  max_input_length: 512
  max_target_length: 128

# Model Configuration
model:
  name: "facebook/bart-base"
  cache_dir: "./models/cache"
  
# Training Configuration
training:
  output_dir: "./models/fine_tuned/bart"
  num_epochs: 3
  batch_size: 8  # BART is slightly larger, so keep at 8
  learning_rate: 5e-5
  weight_decay: 0.01
  warmup_steps: 500
  gradient_accumulation_steps: 1
  fp16: true  # Use mixed precision
  save_steps: 500
  eval_steps: 500
  logging_steps: 100
  save_total_limit: 3
  
# Generation Configuration
generation:
  max_length: 128
  min_length: 30
  num_beams: 4
  length_penalty: 2.0
  early_stopping: true
  no_repeat_ngram_size: 3
  
# Evaluation Configuration
evaluation:
  metrics:
    - rouge
    - bertscore
  batch_size: 16